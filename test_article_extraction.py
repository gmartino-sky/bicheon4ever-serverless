#!/usr/bin/env python3
"""
Script de diagn√≥stico para probar extracci√≥n de art√≠culos del foro MIR4.
Prueba diferentes m√©todos para extraer contenido.
"""

import requests
from bs4 import BeautifulSoup
from newspaper import Article
import logging

logging.basicConfig(level=logging.DEBUG, format='%(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# URL de ejemplo (la que obtuviste en el test)
TEST_URL = "https://forum.mir4global.com/board/patchnote/2040383"

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
    "Accept-Language": "en-US,en;q=0.5",
}

def test_newspaper3k():
    """Prueba extracci√≥n con newspaper3k."""
    print("\n" + "="*60)
    print("M√âTODO 1: newspaper3k")
    print("="*60)
    
    try:
        article = Article(TEST_URL)
        logger.info("üì• Descargando art√≠culo...")
        article.download()
        
        logger.info("üìù Parseando art√≠culo...")
        article.parse()
        
        logger.info(f"‚úÖ T√≠tulo: {article.title}")
        logger.info(f"‚úÖ Texto extra√≠do: {len(article.text)} caracteres")
        
        if article.text:
            print("\nüìÑ Primeros 500 caracteres:")
            print(article.text[:500])
        
        # Intentar NLP
        try:
            logger.info("üß† Generando resumen con NLP...")
            article.nlp()
            logger.info(f"‚úÖ Resumen: {len(article.summary)} caracteres")
            print("\nüìã Resumen:")
            print(article.summary)
            return True
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è NLP fall√≥: {e}")
            return False
            
    except Exception as e:
        logger.error(f"‚ùå Error en newspaper3k: {e}")
        return False

def test_beautifulsoup():
    """Prueba extracci√≥n con BeautifulSoup directo."""
    print("\n" + "="*60)
    print("M√âTODO 2: BeautifulSoup directo")
    print("="*60)
    
    try:
        logger.info("üì• Descargando p√°gina...")
        response = requests.get(TEST_URL, headers=HEADERS, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # Buscar el contenido principal
        # El foro MIR4 usa diferentes selectores
        content_selectors = [
            'div.article_content',
            'div.board_content', 
            'div.post-content',
            'article.article',
            'div.content',
        ]
        
        content = None
        for selector in content_selectors:
            content = soup.select_one(selector)
            if content:
                logger.info(f"‚úÖ Contenido encontrado con selector: {selector}")
                break
        
        if content:
            # Extraer solo texto, sin scripts ni estilos
            for script in content(["script", "style"]):
                script.decompose()
            
            text = content.get_text(separator='\n', strip=True)
            logger.info(f"‚úÖ Texto extra√≠do: {len(text)} caracteres")
            
            print("\nüìÑ Primeros 500 caracteres:")
            print(text[:500])
            
            return text
        else:
            logger.warning("‚ö†Ô∏è No se encontr√≥ contenido con los selectores")
            # Guardar HTML para inspecci√≥n
            with open('debug_page.html', 'w', encoding='utf-8') as f:
                f.write(response.text)
            logger.info("üíæ HTML guardado en debug_page.html para inspecci√≥n")
            return None
            
    except Exception as e:
        logger.error(f"‚ùå Error en BeautifulSoup: {e}")
        return None

def test_requests_with_headers():
    """Prueba descarga con headers espec√≠ficos."""
    print("\n" + "="*60)
    print("M√âTODO 3: Requests con headers completos")
    print("="*60)
    
    try:
        logger.info("üì• Descargando con headers completos...")
        response = requests.get(TEST_URL, headers=HEADERS, timeout=10)
        logger.info(f"‚úÖ Status code: {response.status_code}")
        logger.info(f"‚úÖ Content-Type: {response.headers.get('content-type')}")
        logger.info(f"‚úÖ Tama√±o: {len(response.text)} bytes")
        
        # Verificar si hay contenido
        if 'text/html' in response.headers.get('content-type', ''):
            logger.info("‚úÖ Es HTML v√°lido")
            return True
        else:
            logger.warning("‚ö†Ô∏è No es HTML")
            return False
            
    except Exception as e:
        logger.error(f"‚ùå Error: {e}")
        return False

if __name__ == "__main__":
    print("üîç DIAGN√ìSTICO DE EXTRACCI√ìN DE ART√çCULOS MIR4")
    print("URL de prueba:", TEST_URL)
    print("\nNOTA: Cambia TEST_URL a una URL real del foro si es necesario\n")
    
    # Ejecutar tests
    test_requests_with_headers()
    test_newspaper3k()
    text = test_beautifulsoup()
    
    print("\n" + "="*60)
    print("RESUMEN")
    print("="*60)
    print("Si newspaper3k falla pero BeautifulSoup funciona,")
    print("necesitamos cambiar la funci√≥n extract_and_summarize_article")
    print("para usar BeautifulSoup directamente.")
